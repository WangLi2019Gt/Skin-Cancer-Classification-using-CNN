{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "np.random.seed(123)\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.utils import to_categorical # used for converting labels to one-hot-encoding\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Input,Dense, Dropout, Flatten, Conv2D, MaxPool2D,Conv2DTranspose,Reshape\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "import itertools\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "y_test = [np.argmax(y)for y in y_test]\n",
    "y_train = [np.argmax(y)for y in y_train]\n",
    "x = np.concatenate((x_train, x_test))\n",
    "y = np.concatenate((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate clustering accuracy. Require scikit-learn installed\n",
    "    # Arguments\n",
    "        y: true labels, numpy.array with shape `(n_samples,)`\n",
    "        y_pred: predicted labels, numpy.array with shape `(n_samples,)`\n",
    "    # Return\n",
    "        accuracy, in [0,1]\n",
    "    \"\"\"\n",
    "    y_true = y_true.astype(np.int64)\n",
    "    assert y_pred.size == y_true.size\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "    ind = linear_sum_assignment(w.max() - w)\n",
    "    ind = np.asarray(ind)\n",
    "    ind = np.transpose(ind)\n",
    "    return sum([w[i, j] for i, j in ind]) * 1.0 / y_pred.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = len(np.unique(y))\n",
    "def DeepCluster(input_shape=(75, 100, 3), filters=[32, 64, 128, 7]):\n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(filters[0],kernel_size=(3, 3), padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n",
    "    x = Conv2D(filters[0], kernel_size=(3, 3), padding='same', activation='relu', name='conv2')(x)\n",
    "    x = MaxPool2D(pool_size = (2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(filters[1], kernel_size=(3, 3), padding='same', activation='relu', name='conv3')(x)\n",
    "    x = Conv2D(filters[1], kernel_size=(3, 3), padding='same', activation='relu', name='conv4')(x)\n",
    "    x = MaxPool2D(pool_size = (2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(filters[2], kernel_size=(3, 3), padding='same', activation='relu', name='conv5')(x)\n",
    "    x = Conv2D(filters[2], kernel_size=(3, 3), padding='same', activation='relu', name='conv6')(x)\n",
    "    x = MaxPool2D(pool_size = (2, 2))(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    conv_output = Dense(filters[2], activation='relu')(x)\n",
    "    classifier = Dense(filters[3], activation='softmax')(conv_output)\n",
    "    return  [Model(inputs=input_img, outputs=conv_output, name='conv_output'),Model(inputs=input_img, outputs=classifier, name='classifier')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"conv_output\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 75, 100, 3)]      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 75, 100, 32)       896       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 75, 100, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 37, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 37, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 37, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 18, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 18, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 18, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1769600   \n",
      "=================================================================\n",
      "Total params: 2,056,608\n",
      "Trainable params: 2,056,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"classifier\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 75, 100, 3)]      0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 75, 100, 32)       896       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 75, 100, 32)       9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 37, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 37, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 37, 50, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 18, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 18, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 18, 25, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 9, 12, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 13824)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1769600   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 2,057,511\n",
      "Trainable params: 2,057,511\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_net, Deep_cluster = DeepCluster()\n",
    "conv_net.summary()\n",
    "Deep_cluster.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deep_cluster.compile(optimizer=tf.keras.optimizers.SGD(0.001, 0.9), loss='kld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_distribution(q):\n",
    "    temp =1/(1+q**2)\n",
    "    temp=temp.transpose()/temp.sum(1)\n",
    "    temp=temp.transpose()\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Incorrect number of features. Got 128 features, expected 22500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-262a89f0e358>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mite\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtemp_feature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m# update the auxiliary target distribution p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/environments/tf2_py3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, sample_weight)\u001b[0m\n\u001b[1;32m   1072\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cluster_centers_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1074\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1075\u001b[0m         \u001b[0mx_squared_norms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1076\u001b[0m         return _labels_inertia(X, sample_weight, x_squared_norms,\n",
      "\u001b[0;32m~/environments/tf2_py3/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_check_test_data\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    935\u001b[0m             raise ValueError(\"Incorrect number of features. \"\n\u001b[1;32m    936\u001b[0m                              \"Got %d features, expected %d\" % (\n\u001b[0;32m--> 937\u001b[0;31m                                  n_features, expected_n_features))\n\u001b[0m\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Incorrect number of features. Got 128 features, expected 22500"
     ]
    }
   ],
   "source": [
    "print(n_clusters)\n",
    "#x_1 = x.reshape((x.shape[0], -1))\n",
    "#kmeans = KMeans(n_clusters=n_clusters, n_init=7)\n",
    "#y_pred_last = kmeans.fit_predict(x_1)\n",
    "y_pred_last = np.zeros(10015)\n",
    "loss = 0\n",
    "index = 0\n",
    "maxiter = 8000\n",
    "batch_size = 10\n",
    "update_interval = 60\n",
    "index_array = np.arange(x.shape[0])\n",
    "tol = 0.1 # tolerance threshold to stop training\n",
    "\n",
    "for ite in range(int(maxiter)):\n",
    "    if ite % update_interval == 0:\n",
    "        temp_feature = conv_net.predict(x, verbose=0)\n",
    "        y_pred = kmeans.predict(temp_feature)\n",
    "        q = kmeans.transform(temp_feature)\n",
    "        p = target_distribution(q)# update the auxiliary target distribution p\n",
    "        # evaluate the clustering performance\n",
    "        if y is not None:\n",
    "            accuracy = np.round(acc(y, y_pred), 5)\n",
    "            loss = np.round(loss, 5)\n",
    "            print('Iter %d: accuracy = %.5f,' % (ite, accuracy), ' ; loss=%f'%(loss))\n",
    "\n",
    "        # check stop criterion\n",
    "        delta_label = np.sum(y_pred != y_pred_last).astype(np.float32) / y_pred.shape[0]\n",
    "        print(delta_label)\n",
    "        y_pred_last = np.copy(y_pred)\n",
    "        if (ite > 0 and delta_label < tol):\n",
    "            if(delta_label < tol):\n",
    "                print('delta_label ', delta_label, '< tol ', tol)\n",
    "                print('Reached tolerance threshold. Stopping training.')\n",
    "            break\n",
    "    idx = index_array[index * batch_size: min((index+1) * batch_size, x.shape[0])]\n",
    "    loss = Deep_cluster.train_on_batch(x=x[idx], y=p[idx])\n",
    "    index = index + 1 if (index + 1) * batch_size <= x.shape[0] else 0\n",
    "\n",
    "Deep_cluster.save_weights('./Deep_cluster_model_final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
